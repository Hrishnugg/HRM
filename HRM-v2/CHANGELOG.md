# Changelog

All notable changes to the HRM-v2 project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).

---

## [Unreleased]

### Fixed
- **CRITICAL**: Fixed truncated normal initialization bug in `src/hrm/utils/init.py:48`
  - Corrected `pdf_l` calculation from `c * math.exp(-0.5 * lower ** 2)` to `c * math.exp(-0.5 * upper ** 2)`
  - This bug affected all weight initialization in the model
  - Now matches the original HRM implementation exactly

### Added
- Comprehensive code review report (`/HRM_V2_REVIEW_REPORT.md`)
- Quick reference review summary (`REVIEW_SUMMARY.md`)
- This changelog

### Verified
- All core model logic matches original HRM-ACT-v1 implementation (100% verified)
- ACT halting Q-learning logic is correct
- Sparse embeddings and SignSGD optimizer are correct
- Hierarchical reasoning cycles are correct
- Gradient detachment placement is correct

---

## [0.1.0] - Port Completion

### Added
- Complete HRM-ACT-v1 model port with modern PyTorch infrastructure
- FlashAttention 4 support with graceful SDPA fallback
- Unified attention API (`src/hrm/ops/attention.py`)
- Modular code organization (`ops/`, `models/`, `utils/`)
- Comprehensive type hints and documentation
- Production-ready configuration examples
- Full test suite for HRM-ACT-v1

### Changed
- Modernized buffer registration (from `nn.Buffer` to `register_buffer`)
- Enhanced attention abstraction with unified interface
- Improved code organization and modularity

### Technical
- Target hardware: NVIDIA RTX 5090 (Blackwell, sm_100)
- Software stack: CUDA 12.8+, PyTorch 2.8+, FlashAttention 4
- Python 3.10+

---

## Migration Notes

If you're migrating from the original HRM codebase:

1. **Imports**: Update imports to use the new module structure
   ```python
   # Old:
   from models.hrm.hrm_act_v1 import HierarchicalReasoningModel_ACTV1
   
   # New:
   from hrm.models import HRMACTv1
   ```

2. **API**: The core API remains backward compatible
   - Configuration dicts work the same way
   - Forward pass signatures unchanged
   - Carry state structures identical

3. **Benefits**: The port provides:
   - Modern FlashAttention 4 support
   - Better code organization
   - Comprehensive documentation
   - Type safety with full type hints
   - Production-ready examples

---

## Review History

### Code Review (2024)
- **Reviewer**: Systematic AI code review
- **Scope**: Complete line-by-line comparison with original implementation
- **Files Reviewed**: 7 source files (~1400 lines)
- **Bugs Found**: 1 critical (initialization bug)
- **Status**: All issues resolved âœ…

---

For detailed technical analysis, see:
- **Full Review Report**: `/HRM_V2_REVIEW_REPORT.md`
- **Quick Summary**: `REVIEW_SUMMARY.md`
- **Usage Guide**: `HRM_ACT_V1_GUIDE.md`

